{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is my first DS project in which I developed neural network model which can predict the price of used bicicles (road or mtb)\\nI used two datasets found on kaggle (linki) which included data scraped from two websites, \\nebay.com, bike-exchange.com.\\nThere were 3 significant stages of my project:\\n- cleaning the data \\n\\n- \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### README ###\n",
    "'''\n",
    "This is my first DS project in which I developed neural network model which can predict the price of used bicicles (road or mtb)\n",
    "I used two datasets found on kaggle (linki) which included data scraped from two websites, \n",
    "bike-exchange.com - this dataset was well prepered, with few amount of columns wich contained valuable data\n",
    "ebay.com - dataset included 500 columns which required a lot of struggle to compress the data to 10 cathegories \n",
    "\n",
    "There were 3 significant stages of my project:\n",
    "- cleaning and preprocessing the data: \n",
    "    - merging 2 datasets into one (cleaning/preprocessing functions which I created universal and works god for both datasets)\n",
    "    - grouping types of bike, gropsets, brakes, suspension and extracting year of production, frame material, condition and wheel size  \n",
    "    - filling nans by median in very few instances, where it was safe \n",
    "    - mapping cathegorical data to numeric, I used linear scale for the most columns, although year production had a wide tail, which was flattened with QuantileTransformer from sklearn\n",
    "    - as a result two datasets were made, numerical and cathegorical (one hot encoding)\n",
    "- training model\n",
    "    - \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "df_exch = pd.read_json('data\\\\raw_sources\\data_bike_exchange.json', lines=True)\n",
    "df_ebay = pd.read_json('data\\\\raw_sources\\data_ebay.json', lines=True)\n",
    "\n",
    "df = pd.concat([df_exch, df_ebay], axis = 0).reset_index(drop=True)\n",
    "df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nans_perc(df : (pd.DataFrame, pd.Series), p = False, perc = 0.95, sort_by = 'val'):\n",
    "    n = len(df)\n",
    "    nans_perc = df.isna().sum() / n\n",
    "    print('len - ', n)\n",
    "    if type(df) == pd.DataFrame:\n",
    "        if sort_by == 'val':\n",
    "            nans_perc.sort_values(ascending=True, inplace=True)\n",
    "        else:\n",
    "            nans_perc.sort_index(inplace = True)\n",
    "        if p:\n",
    "            for index, val in nans_perc.items():\n",
    "                print(index + ': ', val)\n",
    "            print('\\n')\n",
    "        cols = nans_perc[nans_perc > 0.95].index\n",
    "        return cols\n",
    "    elif type(df) == pd.Series:\n",
    "        if p:\n",
    "            print('left_nans: ', nans_perc)\n",
    "    return\n",
    "print_nans_perc(df, p = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nans_in_cols(df : pd.DataFrame, cols : list):\n",
    "    print(len(df))\n",
    "    df.dropna(subset=cols, inplace=True)\n",
    "    df.dropna(axis = 1, how = 'all', inplace=True)\n",
    "    print(len(df))\n",
    "    print_nans_perc(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_groups = ['road bike', 'road bike - racing', 'road bike', 'road bike - touring', 'road', 'cyclocross bike', 'cyclocross/gravel', 'road disc bike', 'road bike - racing or touring', \n",
    "            'aero road bike', 'racing/touring roadbike', 'road/touring', 'time trial/triathlon bike', 'road bike racing', 'time trial/triathlon', 'road/racing', 'racing/road bike', \n",
    "            'raod bike', 'road racing bike', 'road bike', 'road bike - touring ??', 'road bike / triathlon', 'racing/road bike', 'comfort road bike',  'road bike', 'road bike / racing bike', 'hybrid', \n",
    "            'gravel, cx, road, commuter', 'road bike / cyclocross bike / triathlon', 'race road bike', 'road bike - racing', 'gravel bike', 'road bike - touring', 'racing bike', 'road bike racing', \"road\", 'road bike', 'road bikes',]\n",
    "\n",
    "mtb_groups = ['mountain bike', 'full suspension', 'downhill bike', 'mountain bike', 'mountain bike/ gravel', 'mountain bike mtb 29er', 'mountain suspension bike', 'hardtail bike','mountain bike', 'mountain  bike style', \n",
    "            'hardtail mountain bike', 'mountain', 'mountain bike', 'mountain bike19\"', 'enduro', '29er mountain bike', 'mountain / jump bike', 'mountain bike mtb 29er', 'hardtail bike', 'downhill bike', 'full suspension mountain bikes', \n",
    "            'hardtail mountain bikes', 'rigid mountain bikes', 'mountain bikes', 'mtb', 'mountain', 'fat bike']\n",
    "\n",
    "types_dict = {'road bike': 'road bike',  'road bike - racing': 'road bike',  'road bike': 'road bike',  'road bike - touring': 'road bike',  'road': 'road bike',  'cyclocross bike': 'road bike',  'cyclocross/gravel': 'road bike',  \n",
    "            'road disc bike': 'road bike',  'road bike - racing or touring': 'road bike',  'aero road bike': 'road bike',  'racing/touring roadbike': 'road bike',  'road/touring': 'road bike',  'time trial/triathlon bike': 'road bike', \n",
    "            'road bike racing': 'road bike',  'time trial/triathlon': 'road bike',  'road/racing': 'road bike',  'racing/road bike': 'road bike',  'raod bike': 'road bike',  'road racing bike': 'road bike',  'road bike': 'road bike',  \n",
    "            'road bike - touring ??': 'road bike',  'road bike / triathlon': 'road bike',  'racing/road bike': 'road bike',  'comfort road bike': 'road bike',   'road bike': 'road bike',  'road bike / racing bike': 'road bike',  'hybrid': 'road bike',  \n",
    "            'gravel, cx, road, commuter': 'road bike',  'road bike / cyclocross bike / triathlon': 'road bike',  'race road bike': 'road bike',  'road bike - racing': 'road bike',  'gravel bike': 'road bike',  'road bike - touring': 'road bike',  \n",
    "            'racing bike': 'road bike',  'road bike racing': 'road bike',  \"road\": 'road bike', 'road bike': 'road bike',  'road bikes': 'road bike', 'mountain bike': 'mtb',  'full suspension': 'full',  'downhill bike': 'full',  'mountain bike': 'mtb',  \n",
    "            'mountain bike/ gravel': 'mtb',  'mountain bike mtb 29er': 'mtb',  'mountain suspension bike': 'mtb',  'hardtail bike': 'hard', 'mountain bike': 'mtb',  'mountain  bike style': 'mtb',  'hardtail mountain bike': 'hard',  'mountain': 'mtb',  \n",
    "            'mountain bike': 'mtb',  'mountain bike19\"': 'mtb',  'enduro': 'full',  '29er mountain bike': 'mtb',  'mountain / jump bike': 'mtb',  'mountain bike mtb 29er': 'mtb',  'hardtail bike': 'hard',  'downhill bike': 'full',  \n",
    "            'full suspension mountain bikes': 'full',  'hardtail mountain bikes': 'hard',  'rigid mountain bikes': 'mtb',  'mountain bikes': 'mtb', 'mountain': 'mtb', 'fat bike': 'mtb'}\n",
    "\n",
    "def find_from_list(row, columns, list):\n",
    "    for col in columns:\n",
    "        value = row[col]\n",
    "        found = ''\n",
    "        if pd.notna(value) and isinstance(value, str): \n",
    "            found = re.findall(r'(' + '|'.join(list) + ')', value, re.IGNORECASE)\n",
    "        if found:\n",
    "            return str(found[0]).lower()\n",
    "    return np.nan\n",
    "\n",
    "def make_num_cat(df_orig : pd.DataFrame, col_name : str, cat_list : list, dictonary: dict, find_cols = [], find_fn = find_from_list, num_type = float):\n",
    "    if find_cols == []:\n",
    "        find_cols = df_orig.columns\n",
    "    cat_col = col_name + '_cat'\n",
    "    num_col = col_name + '_num'\n",
    "    df = df_orig.copy()\n",
    "    df[[cat_col, num_col]] = np.nan\n",
    "    df[cat_col] = df.apply(find_fn, axis = 1, args = (find_cols, cat_list))\n",
    "    print_nans_perc(df[cat_col], p = True)\n",
    "    df[num_col] = df[cat_col].map(dictonary)\n",
    "    df[num_col] = df[num_col].astype(num_type)\n",
    "    return df\n",
    "\n",
    "cols_ty = ['Bike Type', 'Type', 'Title', 'Seller notes', 'Product URL']\n",
    "df = make_num_cat(df, 'type', road_groups + mtb_groups, types_dict, cols_ty, num_type=str)\n",
    "df['type'] = df['type_num']\n",
    "df.drop(columns=['type_num', 'type_cat'], inplace=True)\n",
    "print_nans_perc(df['type'], p=1)\n",
    "df.groupby('type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price'] = df['Price'].combine_first(df['Price now'])\n",
    "df['Price'].replace('[A-Za-z, \\$, Â£]','',inplace=True, regex=True)\n",
    "df = df[df['Price'] != '']\n",
    "df['Price'] = df['Price'].astype(float)\n",
    "print_nans_perc(df['Price'], p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gear_to_group_dict_road = {\n",
    "        '1990 2003': {\n",
    "               8.0: 'sora',\n",
    "               9.0: 'ultegra',\n",
    "        },\n",
    "        '2004 2008': {\n",
    "               8.0:'sora',\n",
    "               9.0: '105',           \n",
    "               10.0: 'dura ace',\n",
    "            },\n",
    "        '2009 2013': {\n",
    "               6.0: 'tourney',\n",
    "               8.0: 'sora',   \n",
    "               9.0: 'deore',\n",
    "               10.0: '105',\n",
    "               11.0: 'ultegra',\n",
    "        },\n",
    "        '2014 2016': {\n",
    "               7.0: 'tourney',\n",
    "               8.0: 'claris',\n",
    "               9.0: 'sora',\n",
    "               10.0: '105',\n",
    "               11.0: 'ultegra',\n",
    "        },\n",
    "        '2017 2023': {\n",
    "               5.0: 'tourney',\n",
    "               6.0: 'tourney',\n",
    "               7.0: 'tourney',\n",
    "               8.0: 'claris',\n",
    "               9.0: 'sora',\n",
    "               10.0: '105',\n",
    "               11.0: 'ultegra',\n",
    "               12.0: 'dura ace',\n",
    "          }         \n",
    "     }\n",
    "gear_to_group_dict_mtb = {\n",
    "          '1990 2003': {\n",
    "               7.0:'altus',\n",
    "               8.0: 'deore',\n",
    "               9.0:'xtr',\n",
    "               },\n",
    "          '2004 2008':{\n",
    "               8.0: 'altus',\n",
    "               9.0: 'deore xt',\n",
    "               10.0:'xtr',\n",
    "          },\n",
    "          '2009 2013': {\n",
    "               6.0: 'tourney',\n",
    "               8.0: 'altus',\n",
    "               9.0: 'deore',\n",
    "               10.0: 'xtr',\n",
    "               11.0: 'ultegra',\n",
    "          },\n",
    "          '2014 2016': {\n",
    "               7.0: 'tourney',\n",
    "               8.0: 'tourney',\n",
    "               9.0: 'altus',\n",
    "               10.0: 'deore xtr',\n",
    "               11.0: 'xtr',\n",
    "          },\n",
    "          '2017 2023': {\n",
    "               5.0: 'tourney',\n",
    "               6.0: 'tourney',\n",
    "               7.0: 'tourney',\n",
    "               8.0: 'tourney',\n",
    "               9.0:'altus',\n",
    "               10.0: 'deore',\n",
    "               11.0: 'deore xt',\n",
    "               12.0:'xtr',\n",
    "          }\n",
    "     }\n",
    "\n",
    "bike_groups = [\n",
    "    \"Dura Ace\", \"Dura-Ace\", \"Ultegra\", \"105\", \"Tiagra\", \"Sora\", \"Claris\", \"GRX\",\n",
    "    \n",
    "    \"XTR\", \"Deore XT\", \"SLX\", \"Deore\", \"Alivio\", \"Acera\", \"Altus\", \"Tourney\", \"Zee\", \"Saint\",\n",
    "    \n",
    "    \"Super Record\", \"Record\", \"Chorus\", \"Potenza\", \"Centaur\", \"Veloce\", \"Athena\",\n",
    "    \n",
    "    \"Sram Red\", \"Force\", \"Rival\", \"Apex\",\n",
    "\n",
    "    \"XX1\", \"X01\",\"GX\", \"NX\", \"SX\", \"XX\", \"X0\", \"X9\", \"X7\", \"X5\", \"Descendant\", \"Code\"\n",
    "]\n",
    "\n",
    "road_groups = [ \"dura ace\", \"dura-ace\", \"ultegra\", \"105\", \"tiagra\", \"sora\", \"claris\", \"grx\",\n",
    "               \"super record\", \"record\", \"chorus\", \"potenza\", \"centaur\", \"veloce\", \"athena\",\n",
    "                \"sram red\", \"Force\", \"arval\", \"apex\"]\n",
    "\n",
    "mtb_groups = [\n",
    "    \"xtr\", \"deore xt\", \"slx\", \"deore\", \"alivio\", \"acera\", \"altus\", \"tourney\", \"zee\", \"saint\",\n",
    "    \"xx1\", \"x01\", \"gx\", \"nx\", \"sx\", \"xx\", \"x0\", \"x9\", \"x7\", \"x5\", \"descendant\", \"code\"\n",
    "]\n",
    "\n",
    "bike_groups_dict = {\n",
    "    \"dura ace\": 1.0, \"dura-ace\": 1.0, \"ultegra\": 0.9, \"105\": 0.8, \"tiagra\": 0.7, \"sora\": 0.6, \"claris\": 0.5, \"grx\": 0.8,\n",
    "    \n",
    "    \"xtr\": 1.0, \"deore xt\": 0.9, \"slx\": 0.8, \"deore\": 0.7, \"alivio\": 0.6, \"acera\": 0.5, \"altus\": 0.4, \"tourney\": 0.3, \"zee\": 0.8, \"saint\": 0.9,\n",
    "    \n",
    "    \"super record\": 1.0, \"record\": 0.9, \"chorus\": 0.8, \"potenza\": 0.7, \"centaur\": 0.6, \"veloce\": 0.5, \"athena\": 0.4,\n",
    "    \n",
    "    \"sram red\": 1.0, \"force\": 0.9, \"rival\": 0.8, \"apex\": 0.7,\n",
    "    \n",
    "    \"xx1\": 1.0, \"x01\": 0.9, \"gx\": 0.8, \"nx\": 0.7, \"sx\": 0.6, \"xx\": 0.9, \"x0\": 0.8, \"x9\": 0.7, \"x7\": 0.6, \"x5\": 0.5, \"descendant\": 0.7, \"code\": 0.7\n",
    "}\n",
    "\n",
    "\n",
    "df.drop(['Color', 'Colour', 'Product URL', 'Photo URL'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_year(row, cols):\n",
    "    for col in cols:\n",
    "        value = row[col]\n",
    "        if pd.notna(value) and isinstance(value, str):\n",
    "            four_num = re.findall(r'\\b[0-9]{4}\\b', value)\n",
    "            four_num = [float(num) for num in four_num]\n",
    "            for num in four_num:\n",
    "                if 1950 <= num <= 2024:\n",
    "                    return num\n",
    "    return np.nan\n",
    "\n",
    "df['Production_year'] = np.nan\n",
    "cols = ['Model Year','Title'] \n",
    "#cols = df.columns\n",
    "df['Production_year'] = df.apply(find_year, axis=1, args=(cols,))\n",
    "print_nans_perc(df['Production_year'], p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_gp = ['Title', 'Seller notes', 'Model', 'Brake Type', 'Gear Change Mechanism', 'Groupset', 'Rear Derailleur']\n",
    "df = make_num_cat(df, 'groupset', bike_groups, bike_groups_dict, cols_gp)\n",
    "df['groupset_cat']\n",
    "df[df['type'] == 'mtb'].groupby('groupset_cat').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['speeds'] = df['Number of Speeds'].combine_first(df['Number of Gears'])\n",
    "df['speeds_num'] = df['speeds'].str.extract(r'\\b(\\d{1,2})\\b').astype(float)\n",
    "\n",
    "def re_count_gears(x):\n",
    "    if x < 5 or x > 33:\n",
    "        return np.nan\n",
    "    elif x <= 12:\n",
    "        return x\n",
    "    else:\n",
    "        if x % 2 == 0:\n",
    "            if x/2 > 12:\n",
    "                return np.nan\n",
    "            else:\n",
    "                return x/2\n",
    "        elif x % 3 == 0:\n",
    "            return x/3\n",
    "\n",
    "speeds_dict_num = {5: 0.2, 6: 0.3, 7: 0.4, 8: 0.5, 9: 0.6, 10: 0.7, 11: 0.8, 12: 0.9}\n",
    "df['speeds_num'] = df['speeds_num'].apply(re_count_gears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds_road_dict_cat = {5: 'tourney', 6: 'tourney', 7: 'claris', 8: 'sora', 9: 'tiagra', 10: '105', 11: 'ultegra', 12: 'dura ace'}\n",
    "speeds_mtb_dict_cat = {5: 'tourney', 6: 'tourney', 7: 'altus', 8: 'acera', 9: 'alivio', 10: 'deore', 11: 'deore xt', 12: 'xtr'}\n",
    "def assign_group(row, gear_to_group_dict_road, gear_to_group_dict_mtb):\n",
    "    bike_type, year, speed = row['type'], row['Production_year'], row['speeds_num']\n",
    "    if pd.isna(speed):\n",
    "        return np.nan\n",
    "    gear_to_group_dict = gear_to_group_dict_road if bike_type == 'Road Bike' else gear_to_group_dict_mtb\n",
    "    if pd.isna(year):\n",
    "        return gear_to_group_dict['2017 2023'][speed]\n",
    "\n",
    "    for time_peroid in gear_to_group_dict:\n",
    "        start, end = map(float, time_peroid.split())\n",
    "        if start <= year <= end:\n",
    "            if speed in gear_to_group_dict[time_peroid]:\n",
    "                return gear_to_group_dict[time_peroid][speed]\n",
    "    return np.nan\n",
    "\n",
    "df['speeds_cat'] = df.apply(assign_group, axis=1, args=(gear_to_group_dict_road, gear_to_group_dict_mtb, ))\n",
    "df['groupset_cat'] = df['groupset_cat'].combine_first(df['speeds_cat'])\n",
    "df['groupset_num'] = df['groupset_cat'].map(bike_groups_dict)\n",
    "\n",
    "print_nans_perc(df['groupset_num'], p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "materials = ['carbon', 'alu', 'aluminium', 'steel', 'alloy', 'titanium', 'chromoly']\n",
    "materials_dict = {'carbon': 0.9, 'alu': 0.5, 'aluminium': 0.5, 'steel': 0.3, 'alloy': 0.5, 'titanium': 0.6, 'chromoly': 0.15}\n",
    "\n",
    "cols_mt = ['Title', 'Seller notes', 'Model', 'Frame Material', 'Material', 'Fork Material', 'Rim Material']\n",
    "df = make_num_cat(df, 'material', materials, materials_dict, find_cols=cols_mt)\n",
    "df['material_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_shift = ['di2', 'axs', 'etap']\n",
    "e_shift_dict = {'di2': 1, 'axs': 1, 'etap': 1, np.nan: 0}\n",
    "\n",
    "e_cols = ['Title', 'Seller notes', 'Model', 'Gear Change Mechanism', 'Features', 'Shifter Style']\n",
    "df = make_num_cat(df, 'e_shift', e_shift, e_shift_dict, find_cols=e_cols)\n",
    "df['e_shift_cat'].fillna('null', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Condition'] != 'for parts or not working']\n",
    "condition_dict = {'used': 0, 'new': 1, 'new other (see details)': 1, 'seller refurbished': 0, 'manufacturer refurbished': 0, '--': 0}\n",
    "\n",
    "df['Condition'] = df['Condition'].combine_first(df['Item condition'])\n",
    "df['isNew'] = df['Condition'].replace(condition_dict, regex=True)\n",
    "df['isNew'] = df['isNew'].astype(float)\n",
    "print_nans_perc(df['isNew'], p = True)\n",
    "df.groupby('isNew').size().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brakes = ['rim', 'disc', 'v-brake', 'hydraulic', 'caliper', 'cantilever', 'v-brakes']\n",
    "brakes_dict = {'rim': 0.5, 'disc': 1, 'v-brake': 0.5, 'hydraulic': 1, 'caliper': 0.5, 'cantilever': 0.5, 'v-brakes': 0.5}\n",
    "\n",
    "cols_br = ['Title', 'Seller notes', 'Model', 'Brake Type', 'Braking Type']\n",
    "df = make_num_cat(df, 'brake', brakes, brakes_dict, find_cols=cols_br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, axs = plt.subplots(2,2, figsize = (8,6))\n",
    "\n",
    "df[df['groupset_cat'] == 'ultegra']['Production_year'].plot(kind='hist', bins=50, title='ultegra', ax=axs[0,0])\n",
    "df[df['groupset_cat'] == '105']['Production_year'].plot(kind='hist', bins=50, title='105', ax=axs[0,1])\n",
    "df[df['groupset_cat'] == 'dura ace']['Production_year'].plot(kind='hist', bins=50, title='dura ace', ax=axs[1,0])\n",
    "df[df['groupset_cat'] == 'sram red']['Production_year'].plot(kind='hist', bins=50, title='sram red', ax=axs[1,1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "groupset_median = df.groupby('groupset_cat')['Production_year'].median()[df.groupby('groupset_cat').size() > 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_nans_perc(df['Production_year'], p = 1)\n",
    "df.loc[df['groupset_cat'].isin(groupset_median.index), 'Production_year'] = df.loc[df['groupset_cat'].isin(groupset_median.index), 'Production_year'].fillna(df['groupset_cat'].map(groupset_median.to_dict()))\n",
    "print_nans_perc(df['Production_year'], p = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "min = 1950\n",
    "max = 2020\n",
    "df['year_num'] = df['Production_year'].apply(lambda x: (x - min)/(max - min))\n",
    "\n",
    "notna_idx = df.index[df['Production_year'].notna()]\n",
    "arr = df.loc[notna_idx, 'Production_year'].to_numpy()\n",
    "arr = arr.reshape(-1, 1)\n",
    "qt = QuantileTransformer(n_quantiles=len(arr), output_distribution='uniform')\n",
    "arr = qt.fit_transform(arr)\n",
    "arr = arr.flatten()\n",
    "df.loc[notna_idx,'year_num'] = arr\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 6)) \n",
    "\n",
    "df['Production_year'].plot(kind='hist', bins=50, ax=axs[0], title='years')\n",
    "df['year_num'].plot(kind='hist', bins=50, ax=axs[1], title='years processed')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "df['year_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = print_nans_perc(df)\n",
    "to_drop = ['Frame Size', 'Department', 'UPC', 'Gender', 'Shifter Style', \n",
    "              'Features', 'Country/Region of Manufacture', 'Tyre Type', 'Style', 'Manufacturer Color', 'Tire Type',\n",
    "              'Modified Item', 'Tires', 'Custom-Built', 'Custom Bundle', 'Handlebar Type', 'Shifter', 'Gear Change Mechanism', \n",
    "              'Model Year', 'Configuration', 'Frame Material', 'Brake Type', 'Condition', 'Number of Gears', 'speeds', 'Number of Speeds', \n",
    "              'Material', 'speeds_num', 'Vintage', 'Model', 'Brand', 'speeds_cat', 'MPN','Size', 'Rear Derailleur', 'Braking Type', \n",
    "              'Groupset', 'Riding Style', 'Frame in inches', 'Size CM', 'Availability', 'Item condition', 'Price was', 'Price now', 'Type', 'Bike Type']\n",
    "to_drop += list(cols)\n",
    "\n",
    "df_drp = df.drop(to_drop, axis = 1, inplace=False)\n",
    "print_nans_perc(df_drp, p=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roadies = df_drp[df_drp['type'] == 'road bike'].reset_index(drop=1)\n",
    "\n",
    "cols_to_drop_road = ['Wheel Size', 'Suspension', 'Suspension Type', 'Seller notes']\n",
    "roadies.drop(columns=cols_to_drop_road, inplace=True)\n",
    "print_nans_perc(roadies, p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_idx = roadies.loc[roadies['Production_year'] < 2016].index\n",
    "roadies.loc[old_idx, 'brake_num'] = 0.5\n",
    "roadies.loc[old_idx, 'brake_cat'] = 'rim'\n",
    "print_nans_perc(roadies['brake_num'], p = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtb = df_drp[df_drp['type'].isin(['mtb', 'full', 'hard'])]\n",
    "\n",
    "print_nans_perc(mtb, p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheel_size = ['26', '27.5', '27', '27.5', '29', '650b', '24']\n",
    "wheel_size_dict = {'27.5': 0.66, '29': 1, '27': 0.66, '27,5': 0.66, '26': 0.33, '650b': 0.66, '24': 0.25}\n",
    "\n",
    "mtb = make_num_cat(mtb, 'wheel', wheel_size, wheel_size_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtb['suspension'] = mtb['Suspension'].combine_first(mtb['Suspension Type'])\n",
    "mtb.drop(columns=['Suspension', 'Suspension Type'], inplace=True)\n",
    "mtb.loc[mtb['suspension'].isin(['full suspension (front & rear)','front & rear (full)']), 'suspension'] = 'full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "susps = ['front', 'full', 'no suspension', 'rear', 'hard']\n",
    "susps_dict = {'front': 0.5, 'full': 1, 'no suspension': 0, 'rear': 1, 'hard': 0.5}\n",
    "\n",
    "sus_cols = ['suspension', 'type']\n",
    "mtb = make_num_cat(mtb, 'susp', susps, susps_dict, find_cols=sus_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_idx = mtb.loc[mtb['Production_year'] > 2010].index\n",
    "mtb.loc[old_idx, 'brake_num'] = 1\n",
    "mtb.loc[old_idx, 'brake_cat'] = 'disc'\n",
    "print_nans_perc(mtb['brake_cat'], p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtb_num = mtb.drop(columns=['groupset_cat', 'brake_cat', 'material_cat', 'type', 'Wheel Size', 'wheel_cat', 'Seller notes', 'Title', 'suspension', 'susp_cat', 'e_shift_cat', 'Production_year'])\n",
    "mtb_cat = mtb.drop(columns=['groupset_num', 'brake_num', 'material_num', 'type', 'Wheel Size', 'wheel_num', 'Seller notes', 'Title', 'suspension', 'susp_num', 'Production_year'])\n",
    "print_nans_perc(mtb_cat, p=True)\n",
    "\n",
    "mtb_num.dropna(axis=0, how='any', inplace=True)\n",
    "mtb_cat.dropna(axis=0, how='any', inplace=True)\n",
    "num_cols = ['ID', 'Price','year_num', 'isNew', 'susp_num','material_num', 'groupset_num', 'e_shift_num', 'wheel_num', 'brake_num']\n",
    "cat_cols = ['ID', 'Price','year_num', 'isNew', 'susp_cat','material_cat', 'groupset_cat', 'e_shift_cat', 'wheel_cat', 'brake_cat']\n",
    "mtb_num = mtb_num[num_cols]\n",
    "mtb_num.to_csv('data\\\\num_data\\mtb_num.csv')\n",
    "\n",
    "mtb_one_hot = pd.get_dummies(mtb_cat, columns=['susp_cat','material_cat', 'groupset_cat', 'e_shift_cat', 'wheel_cat', 'brake_cat'])\n",
    "mtb_cat.to_csv('data\\\\cat_data\\mtb_one_hot.csv')\n",
    "\n",
    "print_nans_perc(roadies, p=True, sort_by='idx')\n",
    "print_nans_perc(roadies.dropna(axis=0, how='any'), p=True, sort_by='idx')\n",
    "roadies_num = roadies.drop(columns=['type', 'Title', 'groupset_cat', 'brake_cat', 'material_cat', 'e_shift_cat', 'Production_year'])\n",
    "roadies_cat = roadies.drop(columns=['groupset_num', 'brake_num', 'material_num', 'type', 'Title', 'e_shift_num', 'Production_year'])\n",
    "roadies_num.dropna(axis=0, how='any', inplace=True)\n",
    "roadies_cat.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "roadies_num.to_csv('data\\\\num_data\\\\road_num.csv')\n",
    "\n",
    "roadies_one_hot = pd.get_dummies(roadies_cat, columns=['groupset_cat', 'brake_cat', 'material_cat', 'e_shift_cat'])\n",
    "roadies_one_hot.to_csv('data\\\\cat_data\\\\road_one_hot.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
